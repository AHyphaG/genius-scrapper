{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genius Lyrics Metadata Scraper\n",
    "\n",
    "Script untuk mengambil metadata (views, release date, song_id) dari halaman Genius berdasarkan URL yang ada di CSV.\n",
    "\n",
    "## Features:\n",
    "- Multi-fallback extraction untuk song_id\n",
    "- Proxy support\n",
    "- Retry mechanism\n",
    "- Batch processing\n",
    "- Output ke CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Input file: lyrics_final_4.csv\n",
      "üìä Batch 11, size: 1000\n",
      "üíæ Output directory: output\n",
      "üåê Using proxies: True\n"
     ]
    }
   ],
   "source": [
    "# --- KONFIGURASI ---\n",
    "INPUT_FILE = \"lyrics_final_4.csv\"\n",
    "BATCH_INDEX = 11\n",
    "SAMPLE_SIZE = 1000\n",
    "WAIT_BETWEEN_REQUESTS = 0.8\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "FINAL_OUTPUT_FILE = f\"{OUTPUT_DIR}/lyrics_final_metadata.csv\"\n",
    "\n",
    "USE_PROXIES = True\n",
    "PROXIES = [\n",
    "    {\n",
    "        \"http\": \"https://td-customer-fKohPcboppa9:oabSMcuisbvj@3cx2lqeo.pr.thordata.net:9999\",\n",
    "        \"https\": \"https://td-customer-fKohPcboppa9:oabSMcuisbvj@3cx2lqeo.pr.thordata.net:9999\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìÅ Input file: {INPUT_FILE}\")\n",
    "print(f\"üìä Batch {BATCH_INDEX}, size: {SAMPLE_SIZE}\")\n",
    "print(f\"üíæ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"üåê Using proxies: {USE_PROXIES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ extract_song_id function defined\n"
     ]
    }
   ],
   "source": [
    "# --- UTIL: Ekstraksi song_id dari HTML (multi-fallback) ---\n",
    "def extract_song_id(html: str):\n",
    "    \"\"\"\n",
    "    Ekstraksi song_id dari HTML dengan multiple fallback methods\n",
    "    \"\"\"\n",
    "    # 1) trackingData: {\"key\":\"Song ID\",\"value\":12345}\n",
    "    m = re.search(r'\"key\"\\s*:\\s*\"Song ID\"\\s*,\\s*\"value\"\\s*:\\s*(\\d+)', html, re.I)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "\n",
    "    # 2) embedContent: data-song-id='12345' (quote bisa dibackslash)\n",
    "    m = re.search(r\"data-song-id\\s*=\\s*\\\\?['\\\"](\\d+)\\\\?['\\\"]\", html, re.I)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "\n",
    "    # 3) pusherChannel: \"song-12345\"\n",
    "    m = re.search(r'\"pusherChannel\"\\s*:\\s*\"song-(\\d+)\"', html, re.I)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "\n",
    "    # 4) dfpKv: ...\"name\":\"song_id\",\"values\":[\"12345\"]\n",
    "    m = re.search(r'\"name\"\\s*:\\s*\"song_id\"\\s*,\\s*\"values\"\\s*:\\s*\\[\\s*\"(\\d+)\"\\s*\\]', html, re.I)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "\n",
    "    # 5) Parse window._PRELOADED_STATE_ baik yang JSON.parse('...') maupun objek langsung\n",
    "    # 5a) JSON.parse('...') ‚Üí perlu 2x json.loads (decode string ‚Üí parse json)\n",
    "    mm = re.search(r\"window\\._PRELOADED_STATE_\\s*=\\s*JSON\\.parse\\(\\s*'(.+?)'\\s*\\)\\s*;\", html, re.S)\n",
    "    if mm:\n",
    "        blob = mm.group(1)\n",
    "        try:\n",
    "            state_str = json.loads(f'\"{blob}\"')  # decode escape dari string JS\n",
    "            state = json.loads(state_str)       # parse JSON jadi dict\n",
    "            sid = (state.get(\"songPage\") or {}).get(\"song\")\n",
    "            if isinstance(sid, (int, str)) and str(sid).isdigit():\n",
    "                return int(sid)\n",
    "            for td in (state.get(\"songPage\") or {}).get(\"trackingData\", []):\n",
    "                if isinstance(td, dict) and td.get(\"key\") == \"Song ID\":\n",
    "                    val = td.get(\"value\")\n",
    "                    if isinstance(val, (int, str)) and str(val).isdigit():\n",
    "                        return int(val)\n",
    "            songs = (state.get(\"entities\") or {}).get(\"songs\", {})\n",
    "            for v in songs.values():\n",
    "                if isinstance(v, dict) and str(v.get(\"id\", \"\")).isdigit():\n",
    "                    return int(v[\"id\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 5b) Objek langsung: window._PRELOADED_STATE_ = { ... };\n",
    "    mm = re.search(r\"window\\._PRELOADED_STATE_\\s*=\\s*(\\{.?\\})\\s;\", html, re.S)\n",
    "    if mm:\n",
    "        try:\n",
    "            state = json.loads(mm.group(1))\n",
    "            sid = (state.get(\"songPage\") or {}).get(\"song\")\n",
    "            if isinstance(sid, (int, str)) and str(sid).isdigit():\n",
    "                return int(sid)\n",
    "            for td in (state.get(\"songPage\") or {}).get(\"trackingData\", []):\n",
    "                if isinstance(td, dict) and td.get(\"key\") == \"Song ID\":\n",
    "                    val = td.get(\"value\")\n",
    "                    if isinstance(val, (int, str)) and str(val).isdigit():\n",
    "                        return int(val)\n",
    "            songs = (state.get(\"entities\") or {}).get(\"songs\", {})\n",
    "            for v in songs.values():\n",
    "                if isinstance(v, dict) and str(v.get(\"id\", \"\")).isdigit():\n",
    "                    return int(v[\"id\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return None\n",
    "\n",
    "print(\"‚úÖ extract_song_id function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main Scraper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_from_genius(url):\n",
    "    \"\"\"\n",
    "    Mengambil metadata (views, release_date, song_id) dari halaman Genius\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/114.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    proxies = PROXIES[0] if USE_PROXIES else None\n",
    "\n",
    "    for _ in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, proxies=proxies, timeout=15)\n",
    "            if response.status_code != 200:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "            time.sleep(3)\n",
    "\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "            # Ambil views dari span[title*=\"views\"]\n",
    "            views = None\n",
    "            view_spans = soup.select(\"span[title*='views']\")\n",
    "            for span in view_spans:\n",
    "                title_text = span.get(\"title\", \"\") or \"\"\n",
    "                match = re.search(r\"([\\d.,]+)\\s+views\", title_text)\n",
    "                if match:\n",
    "                    views_str = match.group(1).replace(\".\", \"\").replace(\",\", \"\")\n",
    "                    if views_str.isdigit():\n",
    "                        views = int(views_str)\n",
    "                    else:\n",
    "                        # last resort: buang non-digit\n",
    "                        views = int(re.sub(r\"\\D\", \"\", views_str))\n",
    "                    break\n",
    "\n",
    "            # === PERBAIKAN RELEASE DATE dengan multiple fallback ===\n",
    "            release_date = None\n",
    "            \n",
    "            # Method 1: Selector asli\n",
    "            metadata_labels = soup.select(\n",
    "                \"div.MetadataStats_Container-sc-8a5f771a-0 span.LabelWithIcon_Label-sc-a1922d73-1\"\n",
    "            )\n",
    "            if metadata_labels:\n",
    "                text = metadata_labels[0].get_text(strip=True)\n",
    "                if re.match(r\"[A-Za-z]{3,}\\.?\\s\\d{1,2},\\s\\d{4}\", text):\n",
    "                    release_date = text\n",
    "\n",
    "            # Method 2: Cari di semua span yang mengandung pattern tanggal\n",
    "            if not release_date:\n",
    "                all_spans = soup.find_all('span')\n",
    "                for span in all_spans:\n",
    "                    text = span.get_text(strip=True)\n",
    "                    # Pattern: \"January 1, 2020\" atau \"Jan 1, 2020\"\n",
    "                    if re.match(r\"[A-Za-z]{3,}\\.?\\s\\d{1,2},\\s\\d{4}\", text):\n",
    "                        release_date = text\n",
    "                        break\n",
    "                    # Pattern: \"Released January 1, 2020\"\n",
    "                    match = re.search(r\"Released\\s+([A-Za-z]{3,}\\.?\\s\\d{1,2},\\s\\d{4})\", text, re.I)\n",
    "                    if match:\n",
    "                        release_date = match.group(1)\n",
    "                        break\n",
    "\n",
    "            # Method 3: Cari di div metadata lain dengan class yang mungkin berubah\n",
    "            if not release_date:\n",
    "                # Cari semua div yang mengandung metadata\n",
    "                metadata_divs = soup.find_all('div', class_=re.compile(r'metadata|stats|info', re.I))\n",
    "                for div in metadata_divs:\n",
    "                    text = div.get_text(strip=True)\n",
    "                    match = re.search(r\"([A-Za-z]{3,}\\.?\\s\\d{1,2},\\s\\d{4})\", text)\n",
    "                    if match:\n",
    "                        release_date = match.group(1)\n",
    "                        break\n",
    "\n",
    "            # Method 4: Cari di semua element yang mengandung kata \"release\"\n",
    "            if not release_date:\n",
    "                try:\n",
    "                    # Gunakan 'string' parameter untuk BeautifulSoup versi baru\n",
    "                    all_elements = soup.find_all(string=re.compile(r'release', re.I))\n",
    "                    for element in all_elements:\n",
    "                        parent = element.parent\n",
    "                        if parent:\n",
    "                            text = parent.get_text(strip=True)\n",
    "                            match = re.search(r\"([A-Za-z]{3,}\\.?\\s\\d{1,2},\\s\\d{4})\", text)\n",
    "                            if match:\n",
    "                                release_date = match.group(1)\n",
    "                                break\n",
    "                except Exception:\n",
    "                    # Fallback untuk versi BeautifulSoup lama\n",
    "                    try:\n",
    "                        all_elements = soup.find_all(text=re.compile(r'release', re.I))\n",
    "                        for element in all_elements:\n",
    "                            parent = element.parent\n",
    "                            if parent:\n",
    "                                text = parent.get_text(strip=True)\n",
    "                                match = re.search(r\"([A-Za-z]{3,}\\.?\\s\\d{1,2},\\s\\d{4})\", text)\n",
    "                                if match:\n",
    "                                    release_date = match.group(1)\n",
    "                                    break\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "            # Method 5: Cari di JSON data (PRELOADED_STATE)\n",
    "            if not release_date:\n",
    "                try:\n",
    "                    # Cari di window._PRELOADED_STATE_\n",
    "                    state_match = re.search(r\"window\\._PRELOADED_STATE_\\s*=\\s*({.*?});\", html, re.S)\n",
    "                    if state_match:\n",
    "                        state_data = json.loads(state_match.group(1))\n",
    "                        # Cari release date di berbagai lokasi dalam state\n",
    "                        song_data = state_data.get(\"entities\", {}).get(\"songs\", {})\n",
    "                        for song in song_data.values():\n",
    "                            if isinstance(song, dict):\n",
    "                                release_info = song.get(\"release_date_for_display\") or song.get(\"releaseDate\")\n",
    "                                if release_info and re.match(r\"[A-Za-z]{3,}\\.?\\s\\d{1,2},\\s\\d{4}\", str(release_info)):\n",
    "                                    release_date = str(release_info)\n",
    "                                    break\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Method 6: Cari pattern tanggal di semua text content\n",
    "            if not release_date:\n",
    "                full_text = soup.get_text()\n",
    "                # Cari semua pattern tanggal dalam format yang umum\n",
    "                date_patterns = [\n",
    "                    r\"([A-Za-z]{3,}\\.?\\s\\d{1,2},\\s\\d{4})\",  # January 1, 2020\n",
    "                    r\"(\\d{1,2}\\s[A-Za-z]{3,}\\.?\\s\\d{4})\",   # 1 January 2020\n",
    "                    r\"(\\d{4}-\\d{2}-\\d{2})\",                 # 2020-01-01\n",
    "                ]\n",
    "                \n",
    "                for pattern in date_patterns:\n",
    "                    matches = re.findall(pattern, full_text)\n",
    "                    for match in matches:\n",
    "                        # Validasi bahwa ini adalah tanggal yang masuk akal (tidak terlalu lama/baru)\n",
    "                        year_match = re.search(r'\\d{4}', match)\n",
    "                        if year_match:\n",
    "                            year = int(year_match.group())\n",
    "                            if 1950 <= year <= 2025:  # Range tahun yang masuk akal\n",
    "                                release_date = match\n",
    "                                break\n",
    "                    if release_date:\n",
    "                        break\n",
    "\n",
    "            # >>> NEW: Ambil song_id dari HTML mentah (bukan dari soup)\n",
    "            song_id = extract_song_id(html)\n",
    "\n",
    "            return {\n",
    "                \"views\": views,\n",
    "                \"release_date\": release_date,\n",
    "                \"song_id\": song_id\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            # Uncomment line di bawah untuk debugging jika diperlukan\n",
    "            # print(f\"     ‚ö†Ô∏è  Error: {str(e)[:50]}...\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return {\n",
    "        \"views\": None,\n",
    "        \"release_date\": None,\n",
    "        \"song_id\": None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset loaded: 20632 total rows\n",
      "üìã Batch info: rows 11000‚Äì12000 (1000 rows)\n",
      "üìã Columns: ['Unnamed: 0', 'song_id', 'song_name', 'artist_id', 'artist_name', 'album_name', 'genre_name', 'musixmatch_url', 'is_music', 'lyrics_clean', 'genius_url', 'lyrics_len', 'views', 'release_date']\n",
      "\n",
      "üìÅ Sample data:\n",
      "       Unnamed: 0    song_id          song_name  artist_id        artist_name  \\\n",
      "11000       11082  123795258   a drawn out exit   10771225  dark tranquillity   \n",
      "11001       11083  120629831              intro   10012426              mocca   \n",
      "11002       11084  128974287       dying inside   11619313            twinnie   \n",
      "11003       11085  111493693  new york new york      17131      frank sinatra   \n",
      "11004       11086  112995089               1994     203046       jason aldean   \n",
      "\n",
      "                          album_name       genre_name  \\\n",
      "11000                         Moment    Barat - Metal   \n",
      "11001                        Colours      Indie - Pop   \n",
      "11002                   Dying Inside  Barat - Country   \n",
      "11003  The Classics (Deluxe Edition)     Barat - Jazz   \n",
      "11004    The Jason Aldean Collection  Barat - Country   \n",
      "\n",
      "                                          musixmatch_url  is_music  \\\n",
      "11000  https://www.musixmatch.com/lyrics/dark-tranqui...      True   \n",
      "11001      https://www.musixmatch.com/lyrics/mocca/intro      True   \n",
      "11002  https://www.musixmatch.com/lyrics/twinnie/dyin...      True   \n",
      "11003  https://www.musixmatch.com/lyrics/frank-sinatr...      True   \n",
      "11004  https://www.musixmatch.com/lyrics/jason-aldean...      True   \n",
      "\n",
      "                                            lyrics_clean  \\\n",
      "11000  So burn the trail and keep the flames alight\\n...   \n",
      "11001  Day by day (day by day)\\nAs time goes by (as t...   \n",
      "11002  It's been seven weeks too long\\nStart to think...   \n",
      "11003  Start spreading the news, I'm leaving today\\nI...   \n",
      "11004  Now, girl, I know you used to the same old sam...   \n",
      "\n",
      "                                              genius_url  lyrics_len views  \\\n",
      "11000  https://genius.com/dark-tranquillity-a-drawn-o...        1100  None   \n",
      "11001              https://genius.com/mocca-intro-lyrics         349  None   \n",
      "11002     https://genius.com/twinnie-dying-inside-lyrics        1780  None   \n",
      "11003  https://genius.com/frank-sinatra-new-york-new-...        1065  None   \n",
      "11004        https://genius.com/jason-aldean-1994-lyrics        2058  None   \n",
      "\n",
      "      release_date  \n",
      "11000         None  \n",
      "11001         None  \n",
      "11002         None  \n",
      "11003         None  \n",
      "11004         None  \n"
     ]
    }
   ],
   "source": [
    "# --- LOAD DATA ---\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {INPUT_FILE}\")\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "start_idx = BATCH_INDEX * SAMPLE_SIZE\n",
    "end_idx = start_idx + SAMPLE_SIZE\n",
    "df_batch = df.iloc[start_idx:end_idx].copy()\n",
    "\n",
    "if \"views\" not in df_batch.columns:\n",
    "    df_batch[\"views\"] = None\n",
    "if \"release_date\" not in df_batch.columns:\n",
    "    df_batch[\"release_date\"] = None\n",
    "if \"song_id\" not in df_batch.columns:\n",
    "    df_batch[\"song_id\"] = None  # <<< NEW kolom\n",
    "\n",
    "print(f\"üìä Dataset loaded: {len(df)} total rows\")\n",
    "print(f\"üìã Batch info: rows {start_idx}‚Äì{end_idx} ({len(df_batch)} rows)\")\n",
    "print(f\"üìã Columns: {list(df_batch.columns)}\")\n",
    "print(f\"\\nüìÅ Sample data:\")\n",
    "print(df_batch.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Scraping Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Mulai scraping batch 11 (baris 11000‚Äì12000)\n",
      "\n",
      "üîç [11000] dark tranquillity ‚Äì a drawn out exit\n",
      "     üåê URL: https://genius.com/dark-tranquillity-a-drawn-out-exit-lyrics\n",
      "     üìÖ Release date : Nov. 20, 2020\n",
      "     üÜî Song ID      : 5947087\n",
      "\n",
      "üîç [11001] mocca ‚Äì intro\n",
      "     üåê URL: https://genius.com/mocca-intro-lyrics\n",
      "     üìÖ Release date : Not found\n",
      "     üÜî Song ID      : 1273694\n",
      "\n",
      "üîç [11002] twinnie ‚Äì dying inside\n",
      "     üåê URL: https://genius.com/twinnie-dying-inside-lyrics\n",
      "     üìÖ Release date : Apr. 22, 2022\n",
      "     üÜî Song ID      : 7933123\n",
      "\n",
      "üîç [11003] frank sinatra ‚Äì new york new york\n",
      "     üåê URL: https://genius.com/frank-sinatra-new-york-new-york-lyrics\n",
      "     ‚úÖ Views        : 607360\n",
      "     üìÖ Release date : Mar. 26, 1980\n",
      "     üÜî Song ID      : 4260\n",
      "\n",
      "üîç [11004] jason aldean ‚Äì 1994\n",
      "     üåê URL: https://genius.com/jason-aldean-1994-lyrics\n",
      "     üìÖ Release date : Oct. 16, 2012\n",
      "     üÜî Song ID      : 156359\n",
      "\n",
      "üîç [11005] shaun ‚Äì dream\n",
      "     üåê URL: https://genius.com/shaun-dream-lyrics\n",
      "     üìÖ Release date : Dec. 25, 2017\n",
      "     üÜî Song ID      : 3393992\n",
      "\n",
      "üîç [11006] cline dion ‚Äì des milliers de baisers\n",
      "     üåê URL: https://genius.com/celine-dion-des-milliers-de-baisers-lyrics\n",
      "     üìÖ Release date : Oct. 14, 2003\n",
      "     üÜî Song ID      : 315567\n",
      "\n",
      "üîç [11007] ecko show ‚Äì ada sayang ada\n",
      "     üåê URL: https://genius.com/ecko-show-ada-sayang-ada-lyrics\n",
      "     ‚ùå Gagal mengambil metadata.\n",
      "\n",
      "üîç [11008] ateez ‚Äì halazia\n",
      "     üåê URL: https://genius.com/ateez-halazia-lyrics\n",
      "     ‚úÖ Views        : 41984\n",
      "     üìÖ Release date : Dec. 30, 2022\n",
      "     üÜî Song ID      : 8658664\n",
      "\n",
      "üîç [11009] anime allstars ‚Äì vertrau mir digimon akustikversion\n",
      "     üåê URL: https://genius.com/anime-allstars-vertrau-mir-digimon-akustik-version-lyrics\n",
      "     üìÖ Release date : Sep. 6, 2019\n",
      "     üÜî Song ID      : 8483815\n",
      "\n",
      "üîç [11010] major lazer ‚Äì all my love feat ariana grande machel montano remix\n",
      "     üåê URL: https://genius.com/major-lazer-all-my-love-remix-lyrics\n",
      "     ‚úÖ Views        : 34097\n",
      "     üìÖ Release date : Jun. 1, 2015\n",
      "     üÜî Song ID      : 1872618\n",
      "\n",
      "üîç [11011] michael schenker group ‚Äì under attack\n",
      "     üåê URL: https://genius.com/michael-schenker-group-under-attack-lyrics\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüöÄ Mulai scraping batch {BATCH_INDEX} (baris {start_idx}‚Äì{end_idx})\\n\")\n",
    "\n",
    "for idx, row in df_batch.iterrows():\n",
    "    url = row.get(\"genius_url\", \"\")\n",
    "    song = row.get(\"song_name\", \"\")\n",
    "    artist = row.get(\"artist_name\", \"\")\n",
    "\n",
    "    print(f\"üîç [{idx}] {artist} ‚Äì {song}\")\n",
    "    print(f\"     üåê URL: {url}\")\n",
    "\n",
    "    if pd.isna(url) or not url.strip():\n",
    "        print(\"     ‚ö†Ô∏è  URL kosong ‚Üí dilewati.\\n\")\n",
    "        continue\n",
    "\n",
    "    metadata = get_metadata_from_genius(url)\n",
    "    df_batch.at[idx, \"views\"] = metadata.get(\"views\")\n",
    "    df_batch.at[idx, \"release_date\"] = metadata.get(\"release_date\")\n",
    "    df_batch.at[idx, \"song_id\"] = metadata.get(\"song_id\")\n",
    "\n",
    "    if metadata.get(\"views\") or metadata.get(\"release_date\") or metadata.get(\"song_id\") is not None:\n",
    "        if metadata.get(\"views\"):\n",
    "            print(f\"     ‚úÖ Views        : {metadata.get('views')}\")\n",
    "        else:\n",
    "            print(f\"     ‚úÖ Views        : Not found\")\n",
    "        if metadata.get(\"release_date\"):\n",
    "            print(f\"     üìÖ Release date : {metadata.get('release_date')}\")\n",
    "        else:\n",
    "            print(f\"     üìÖ Release date : Not found\")\n",
    "        print(f\"     üÜî Song ID      : {metadata.get('song_id') if metadata.get('song_id') is not None else 'Not found'}\\n\")\n",
    "    else:\n",
    "        print(f\"     ‚ùå Gagal mengambil metadata.\\n\")\n",
    "\n",
    "    time.sleep(WAIT_BETWEEN_REQUESTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SIMPAN KE FILE FINAL ---\n",
    "if os.path.exists(FINAL_OUTPUT_FILE):\n",
    "    df_existing = pd.read_csv(FINAL_OUTPUT_FILE)\n",
    "    df_combined = pd.concat([df_existing, df_batch], ignore_index=True)\n",
    "    df_combined.drop_duplicates(\n",
    "        subset=[\"song_name\", \"artist_name\", \"genius_url\"],\n",
    "        keep=\"last\",\n",
    "        inplace=True\n",
    "    )\n",
    "    print(f\"üìã Combined with existing data: {len(df_existing)} + {len(df_batch)} = {len(df_combined)} rows\")\n",
    "else:\n",
    "    df_combined = df_batch\n",
    "    print(f\"üìã New file created with {len(df_combined)} rows\")\n",
    "\n",
    "df_combined.to_csv(FINAL_OUTPUT_FILE, index=False)\n",
    "print(f\"\\n‚úÖ Metadata batch {BATCH_INDEX} disimpan ke: {FINAL_OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# --- FUNGSI ANALISIS DATA ---\n",
    "def analyze_scraped_data(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Melakukan analisis dasar pada data yang sudah di-scrape\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Views distribution\n",
    "    plt.subplot(2, 2, 1)\n",
    "    views_data = df['views'].dropna()\n",
    "    if len(views_data) > 0:\n",
    "        plt.hist(views_data, bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "        plt.xlabel('Views')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of Song Views')\n",
    "        plt.yscale('log')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No views data available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Distribution of Song Views - No Data')\n",
    "    \n",
    "    # Release years\n",
    "    plt.subplot(2, 2, 2)\n",
    "    release_years = df['release_date'].dropna().str.extract(r'(\\d{4})')[0]\n",
    "    if len(release_years) > 0:\n",
    "        release_years = release_years.astype(int)\n",
    "        plt.hist(release_years, bins=20, edgecolor='black', alpha=0.7, color='lightgreen')\n",
    "        plt.xlabel('Release Year')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of Release Years')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No release date data available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Distribution of Release Years - No Data')\n",
    "    \n",
    "    # Success rates\n",
    "    plt.subplot(2, 2, 3)\n",
    "    success_rates = [\n",
    "        df['views'].notna().mean() * 100,\n",
    "        df['release_date'].notna().mean() * 100,\n",
    "        df['song_id'].notna().mean() * 100\n",
    "    ]\n",
    "    labels = ['Views', 'Release Date', 'Song ID']\n",
    "    bars = plt.bar(labels, success_rates, color=['skyblue', 'lightgreen', 'salmon'], alpha=0.8)\n",
    "    plt.ylabel('Success Rate (%)')\n",
    "    plt.title('Metadata Extraction Success Rates')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Tambahkan nilai di atas bar\n",
    "    for bar, rate in zip(bars, success_rates):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{rate:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Top artists by average views\n",
    "    plt.subplot(2, 2, 4)\n",
    "    artist_views = df.groupby('artist_name')['views'].mean().dropna().sort_values(ascending=False).head(10)\n",
    "    if len(artist_views) > 0:\n",
    "        plt.barh(range(len(artist_views)), artist_views.values, color='coral', alpha=0.8)\n",
    "        plt.yticks(range(len(artist_views)), artist_views.index)\n",
    "        plt.xlabel('Average Views')\n",
    "        plt.title('Top 10 Artists by Average Views')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Format x-axis untuk views yang besar\n",
    "        ax = plt.gca()\n",
    "        ax.ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No artist views data available', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Top 10 Artists by Average Views - No Data')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nüìä DATA ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_songs = len(df)\n",
    "    print(f\"üìà Total songs processed: {total_songs}\")\n",
    "    \n",
    "    if len(views_data) > 0:\n",
    "        print(f\"üìä Views statistics:\")\n",
    "        print(f\"   ‚Ä¢ Mean: {views_data.mean():,.0f}\")\n",
    "        print(f\"   ‚Ä¢ Median: {views_data.median():,.0f}\")\n",
    "        print(f\"   ‚Ä¢ Max: {views_data.max():,.0f}\")\n",
    "        print(f\"   ‚Ä¢ Min: {views_data.min():,.0f}\")\n",
    "    \n",
    "    if len(release_years) > 0:\n",
    "        print(f\"üìÖ Release year range: {release_years.min()} - {release_years.max()}\")\n",
    "        print(f\"üìÖ Most common release year: {release_years.mode().iloc[0] if not release_years.mode().empty else 'N/A'}\")\n",
    "    \n",
    "    # Top artists info\n",
    "    if len(artist_views) > 0:\n",
    "        print(f\"üé§ Top artist by avg views: {artist_views.index[0]} ({artist_views.iloc[0]:,.0f} views)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Success rates:\")\n",
    "    print(f\"   ‚Ä¢ Views: {success_rates[0]:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Release dates: {success_rates[1]:.1f}%\") \n",
    "    print(f\"   ‚Ä¢ Song IDs: {success_rates[2]:.1f}%\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SUMMARY ---\n",
    "print(\"\\nüìä SCRAPING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "views_count = df_batch['views'].notna().sum()\n",
    "date_count = df_batch['release_date'].notna().sum()\n",
    "id_count = df_batch['song_id'].notna().sum()\n",
    "\n",
    "print(f\"üìà Views extracted: {views_count}/{len(df_batch)} ({views_count/len(df_batch)*100:.1f}%)\")\n",
    "print(f\"üìÖ Release dates extracted: {date_count}/{len(df_batch)} ({date_count/len(df_batch)*100:.1f}%)\")\n",
    "print(f\"üÜî Song IDs extracted: {id_count}/{len(df_batch)} ({id_count/len(df_batch)*100:.1f}%)\")\n",
    "\n",
    "# === TAMBAHAN: ANALISIS DATA ===\n",
    "print(f\"\\nüîç Menjalankan analisis data...\")\n",
    "try:\n",
    "    # Analisis data yang baru saja di-scrape (batch ini)\n",
    "    print(\"\\nüìä ANALISIS BATCH SAAT INI:\")\n",
    "    analyze_scraped_data(df_batch)\n",
    "    \n",
    "    # Jika ingin analisis data keseluruhan (termasuk batch sebelumnya)\n",
    "    if os.path.exists(FINAL_OUTPUT_FILE):\n",
    "        df_all = pd.read_csv(FINAL_OUTPUT_FILE)\n",
    "        print(\"\\nüìä ANALISIS DATA KESELURUHAN:\")\n",
    "        analyze_scraped_data(df_all)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error dalam analisis: {e}\")\n",
    "    print(\"üí° Pastikan matplotlib dan seaborn sudah terinstall: pip install matplotlib seaborn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- SUMMARY ---\n",
    "# print(\"\\nüìä SCRAPING SUMMARY\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# # Count successful extractions\n",
    "# views_count = df_batch['views'].notna().sum()\n",
    "# date_count = df_batch['release_date'].notna().sum()\n",
    "# id_count = df_batch['song_id'].notna().sum()\n",
    "\n",
    "# print(f\"üìà Views extracted: {views_count}/{len(df_batch)} ({views_count/len(df_batch)*100:.1f}%)\")\n",
    "# print(f\"üìÖ Release dates extracted: {date_count}/{len(df_batch)} ({date_count/len(df_batch)*100:.1f}%)\")\n",
    "# print(f\"üÜî Song IDs extracted: {id_count}/{len(df_batch)} ({id_count/len(df_batch)*100:.1f}%)\")\n",
    "\n",
    "# print(f\"\\nüìÅ Final output file: {FINAL_OUTPUT_FILE}\")\n",
    "# print(f\"üìä Total rows in final file: {len(df_combined)}\")\n",
    "\n",
    "# # Show sample of results\n",
    "# print(f\"\\nüìã Sample results:\")\n",
    "# sample_data = df_batch[['song_name', 'artist_name', 'views', 'release_date', 'song_id']].head()\n",
    "# print(sample_data.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
